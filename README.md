# Sistema de Detec√ß√£o e Contagem de T√™nis com YOLOv8

## Desafio T√©cnico ‚Äì Dev Backend com foco em IA

Este projeto √© a minha solu√ß√£o para o Desafio T√©cnico proposto, que consiste em criar um sistema de vis√£o computacional para detectar, rastrear e contar t√™nis em uma √°rea definida, simulando um processo de coleta em um ambiente com vis√£o limitada.

O sistema foi desenvolvido em Python, utilizando um modelo de detec√ß√£o de objetos **YOLOv8** customizado, e a biblioteca **OpenCV** para o processamento de v√≠deo e a l√≥gica de rastreamento.

---

### üé• V√≠deo de Apresenta√ß√£o
https://drive.google.com/file/d/1qNgVfnb4zVxoT2aygI4ZWrR46_ByN7RU/view?usp=sharing

---

### ‚ú® Funcionalidades Principais

* **Treinamento de Modelo Customizado:** Script (`train.py`) para treinar um modelo YOLOv8 a partir de um dataset de imagens de t√™nis.
* **Detec√ß√£o de Objetos:** Utiliza o modelo treinado para detectar t√™nis em um stream de v√≠deo.
* **Regi√£o de Interesse (ROI):** Permite que o usu√°rio defina interativamente a √°rea de monitoramento no in√≠cio da execu√ß√£o.
* **Rastreamento de Objetos (Tracking):** Implementa um rastreador de centroides para atribuir um ID √∫nico a cada t√™nis, permitindo o acompanhamento individual ao longo do tempo.
* **L√≥gica de Coleta:** Detecta quando um t√™nis rastreado desaparece da ROI por um per√≠odo determinado, registrando-o como "coletado".
* **Contagem em Tempo Real:** Exibe na tela os contadores atualizados de `Total Detectado`, `Coletados` e `Restantes na Cena`.
* **Relat√≥rio Final:** Gera um relat√≥rio consolidado no terminal ao final da execu√ß√£o.

---

### üõ†Ô∏è Tecnologias Utilizadas

* **Python 3.10+**
* **PyTorch:** Framework base para o funcionamento do YOLOv8.
* **Ultralytics YOLOv8:** Para treinamento e infer√™ncia do modelo de detec√ß√£o de objetos.
* **OpenCV-Python:** Para manipula√ß√£o de v√≠deo, defini√ß√£o da ROI e visualiza√ß√µes.
* **NumPy:** Para c√°lculos matriciais e manipula√ß√£o de arrays.

---

### ‚öôÔ∏è Configura√ß√£o e Instala√ß√£o

**1. Clone o Reposit√≥rio**
```bash
git clone https://github.com/saraivajv/shoes-processing
cd shoes-processing
```

**2. Crie e Ative um Ambiente Virtual (Recomendado)**
```bash
# Para Linux/macOS
python3 -m venv venv
source venv/bin/activate

# Para Windows
python -m venv venv
.\venv\Scripts\activate
```

**3. Instale as Depend√™ncias**
As depend√™ncias principais podem ser instaladas via pip.
```bash
pip install ultralytics opencv-python numpy
```
*(Nota: A biblioteca `ultralytics` instalar√° o `PyTorch` e outras depend√™ncias necess√°rias automaticamente.)*

**4. Estrutura de Arquivos**
Certifique-se de que o modelo treinado (`best.pt`) e o v√≠deo de simula√ß√£o (`video_simulacao.mp4`) estejam nos caminhos corretos, conforme especificado no topo do script `main.py`.

---

### ‚ñ∂Ô∏è Como Executar

O projeto √© dividido em duas partes principais: treinamento (opcional, pois o modelo j√° est√° treinado) e execu√ß√£o.

**1. Treinamento (Opcional)**
Para treinar o modelo do zero, voc√™ precisar√° de um dataset no formato YOLO e um arquivo `data.yaml` configurado.
```bash
python train.py
```
O melhor modelo ser√° salvo no diret√≥rio `runs/detect/yolov8_tenis_detector/weights/best.pt`.

**2. Execu√ß√£o Principal (Detec√ß√£o e Contagem)**
Este √© o script principal que executa a solu√ß√£o completa.
```bash
python main.py
```
**Instru√ß√µes de Intera√ß√£o:**
1.  Ao executar, uma janela com o primeiro frame do v√≠deo aparecer√°.
2.  **Clique e arraste o mouse** para desenhar um ret√¢ngulo sobre a √°rea que deseja monitorar (a ROI).
3.  Pressione **ENTER** ou **ESPA√áO** para confirmar.
4.  A detec√ß√£o e o rastreamento come√ßar√£o, e os resultados ser√£o exibidos em tempo real. Pressione **'q'** para sair.

---

### üß† L√≥gica e Decis√µes T√©cnicas

A solu√ß√£o foi constru√≠da sobre duas camadas principais: detec√ß√£o e rastreamento.

1.  **Detector (YOLOv8):** A escolha do YOLOv8 se deu por sua alta performance e facilidade de customiza√ß√£o. O *transfer learning* a partir do modelo `yolov8n` permitiu alcan√ßar bons resultados com um tempo de treinamento relativamente curto.

2.  **Rastreador (Tracker):** Foi implementado um rastreador de centroides simples, baseado na **dist√¢ncia euclidiana**. Ele associa detec√ß√µes em frames consecutivos ao ID existente mais pr√≥ximo, o que √© eficiente para objetos que n√£o se movem de forma extremamente err√°tica.

3.  **Robustez e Refinamentos:** Para lidar com os desafios de um cen√°rio real (oclus√µes, detec√ß√µes inst√°veis), foram implementados os seguintes refinamentos:
    * **Per√≠odo de Inicializa√ß√£o:** Os primeiros `80` frames s√£o usados para o sistema "aprender" a cena e estabilizar a contagem inicial de objetos, evitando que "piscadas" na detec√ß√£o sejam contadas como coletas.
    * **Filtro de Ru√≠do:** Detec√ß√µes com uma √°rea em pixels muito pequena s√£o descartadas para evitar que ru√≠dos do modelo criem "t√™nis fantasmas" e inflem a contagem.
    * **Ajuste de NMS (IoU Threshold):** O limiar de Interse√ß√£o sobre Uni√£o foi ajustado para `0.4` para que o detector lide melhor com t√™nis que est√£o muito pr√≥ximos uns dos outros.

---

### üöÄ Melhorias Futuras

* **Aprimoramento do Modelo:** Treinar com um dataset mais diverso (mais fundos, ilumina√ß√µes e oclus√µes) e por mais √©pocas para melhorar a detec√ß√£o de objetos em condi√ß√µes desafiadoras.
* **Implementar um Rastreador Avan√ßado:** Utilizar algoritmos como **SORT** ou **DeepSORT**, que s√£o mais robustos a oclus√µes longas e trocas de ID.
* **Diferencia√ß√£o de Pares:** Evoluir o modelo para n√£o apenas detectar "t√™nis", mas tamb√©m para classificar se √© um p√© direito ou esquerdo, permitindo a contagem de pares.
* **API Backend:** Expor a funcionalidade do sistema atrav√©s de uma API REST, onde um cliente poderia enviar um v√≠deo e receber o relat√≥rio final como um JSON.

---
**Autor:** Jo√£o Victor G. de A. Saraiva
